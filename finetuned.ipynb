{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-20T19:36:57.615229Z",
     "start_time": "2025-05-20T19:36:57.307588Z"
    }
   },
   "source": [
    "import os\n",
    "import torch\n",
    "import torchaudio\n",
    "from datasets import Dataset, Audio\n",
    "from transformers import Wav2Vec2Processor, Wav2Vec2ForCTC, TrainingArguments, Trainer\n",
    "from jiwer import wer\n"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T08:32:56.652588Z",
     "start_time": "2025-05-21T08:32:56.590671Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_data(data_dir=\"sample_data\"):\n",
    "    data = []\n",
    "    for i in range(1, 6):\n",
    "        wav_path = os.path.join(data_dir, f\"recording{i}.wav\")\n",
    "        txt_path = os.path.join(data_dir, f\"recording{i}.txt\")\n",
    "        with open(txt_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            transcript = f.read().strip().lower()\n",
    "        data.append({\"path\": wav_path, \"text\": transcript})\n",
    "    return Dataset.from_list(data)\n",
    "dataset = load_data()\n",
    "dataset = dataset.cast_column(\"path\", Audio(sampling_rate=16000))\n"
   ],
   "id": "f368d4353ed63ed6",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T19:37:16.469368Z",
     "start_time": "2025-05-20T19:37:02.934877Z"
    }
   },
   "cell_type": "code",
   "source": "processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
   "id": "4fee09a2d837e342",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/5 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d982c6d98ef04c10932b739575b7ae62"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T08:49:52.567864Z",
     "start_time": "2025-05-21T08:49:52.562098Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def prepare_example(batch):\n",
    "    if batch[\"text\"].strip() == \"\":\n",
    "        return None\n",
    "    speech_array = batch[\"path\"][\"array\"]\n",
    "    sampling_rate = batch[\"path\"][\"sampling_rate\"]\n",
    "    inputs = processor.feature_extractor(speech_array, sampling_rate=sampling_rate)\n",
    "    batch[\"input_values\"] = inputs[\"input_values\"][0]\n",
    "    batch[\"labels\"] = processor.tokenizer(batch[\"text\"]).input_ids\n",
    "\n",
    "    return batch\n"
   ],
   "id": "3264d2ecec61e197",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T08:50:03.539033Z",
     "start_time": "2025-05-21T08:49:53.491773Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset = dataset.map(\n",
    "    prepare_example,\n",
    "    batch_size=1,\n",
    "    num_proc=1,\n",
    "    load_from_cache_file=False\n",
    ")\n",
    "dataset = dataset.filter(lambda x: x is not None)\n"
   ],
   "id": "169c6d6fa0425180",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/5 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fd8a904cc1914b43bcca7ba8c2f46e1d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Filter:   0%|          | 0/4 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "11e8baed04a64502874cf2558b1433a4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T08:34:28.240848Z",
     "start_time": "2025-05-21T08:34:28.235457Z"
    }
   },
   "cell_type": "code",
   "source": "print(dataset.column_names)\n",
   "id": "362680c8586b0e23",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['path', 'text']\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T19:37:24.440523Z",
     "start_time": "2025-05-20T19:37:23.815522Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = Wav2Vec2ForCTC.from_pretrained(\n",
    "    \"facebook/wav2vec2-base-960h\",\n",
    "    ctc_loss_reduction=\"mean\",\n",
    "    pad_token_id=processor.tokenizer.pad_token_id,\n",
    ")"
   ],
   "id": "797d95011562101b",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T09:04:35.526266Z",
     "start_time": "2025-05-21T09:04:35.520286Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class DataCollatorCTCWithPadding:\n",
    "    def __init__(self, processor, padding=True):\n",
    "        self.processor = processor\n",
    "        self.padding = padding\n",
    "    def __call__(self, features):\n",
    "        input_features = [{\"input_values\": f[\"input_values\"]} for f in features]\n",
    "        batch = self.processor.feature_extractor.pad(\n",
    "            input_features,\n",
    "            padding=self.padding,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        with self.processor.as_target_processor():\n",
    "            label_features = [{\"input_ids\": f[\"labels\"]} for f in features]\n",
    "            labels_batch = self.processor.tokenizer.pad(\n",
    "                label_features,\n",
    "                padding=self.padding,\n",
    "                return_tensors=\"pt\"\n",
    "            )\n",
    "        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n",
    "        batch[\"labels\"] = labels\n",
    "        return batch\n",
    "data_collator = DataCollatorCTCWithPadding(processor=processor)"
   ],
   "id": "b0485345c92db473",
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T19:37:34.815153Z",
     "start_time": "2025-05-20T19:37:34.809828Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from jiwer import wer\n",
    "def compute_metrics(pred):\n",
    "    pred_ids = torch.argmax(torch.tensor(pred.predictions), dim=-1)\n",
    "    pred_str = processor.batch_decode(pred_ids)\n",
    "    label_str = processor.batch_decode(pred.label_ids, group_tokens=False)\n",
    "    return {\"wer\": wer(label_str, pred_str)}\n"
   ],
   "id": "debae8573ce50bad",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T19:21:25.775501Z",
     "start_time": "2025-05-20T19:21:02.753115Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install --upgrade transformers\n",
   "id": "3e68f43b7675e995",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\alper\\miniconda3\\lib\\site-packages (4.51.3)\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.52.0-py3-none-any.whl.metadata (38 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\alper\\miniconda3\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in c:\\users\\alper\\appdata\\roaming\\python\\python312\\site-packages (from transformers) (0.31.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\alper\\miniconda3\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\alper\\miniconda3\\lib\\site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\alper\\miniconda3\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\alper\\miniconda3\\lib\\site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in c:\\users\\alper\\miniconda3\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\alper\\miniconda3\\lib\\site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\alper\\miniconda3\\lib\\site-packages (from transformers) (0.5.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\alper\\miniconda3\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\alper\\miniconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2024.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\alper\\miniconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\alper\\miniconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\alper\\miniconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\alper\\miniconda3\\lib\\site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\alper\\miniconda3\\lib\\site-packages (from requests->transformers) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\alper\\miniconda3\\lib\\site-packages (from requests->transformers) (2025.4.26)\n",
      "Downloading transformers-4.52.0-py3-none-any.whl (10.5 MB)\n",
      "   ---------------------------------------- 0.0/10.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/10.5 MB 991.0 kB/s eta 0:00:11\n",
      "   ---------------------------------------- 0.1/10.5 MB 1.2 MB/s eta 0:00:09\n",
      "    --------------------------------------- 0.2/10.5 MB 1.5 MB/s eta 0:00:07\n",
      "   - -------------------------------------- 0.5/10.5 MB 2.5 MB/s eta 0:00:04\n",
      "   -- ------------------------------------- 0.7/10.5 MB 3.1 MB/s eta 0:00:04\n",
      "   --- ------------------------------------ 1.0/10.5 MB 3.7 MB/s eta 0:00:03\n",
      "   ---- ----------------------------------- 1.2/10.5 MB 3.9 MB/s eta 0:00:03\n",
      "   ---- ----------------------------------- 1.2/10.5 MB 3.9 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 1.7/10.5 MB 4.1 MB/s eta 0:00:03\n",
      "   -------- ------------------------------- 2.2/10.5 MB 5.0 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 2.5/10.5 MB 4.8 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 2.5/10.5 MB 4.8 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 2.8/10.5 MB 4.8 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 3.4/10.5 MB 5.1 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 3.7/10.5 MB 5.2 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 3.9/10.5 MB 5.2 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 4.2/10.5 MB 5.2 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 4.4/10.5 MB 5.3 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 4.7/10.5 MB 5.2 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 4.9/10.5 MB 5.2 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 5.2/10.5 MB 5.3 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 5.5/10.5 MB 5.3 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 5.8/10.5 MB 5.3 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 6.1/10.5 MB 5.4 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 6.2/10.5 MB 5.3 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 6.5/10.5 MB 5.3 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 6.8/10.5 MB 5.3 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 6.9/10.5 MB 5.3 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 7.3/10.5 MB 5.4 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 7.5/10.5 MB 5.4 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 7.8/10.5 MB 5.3 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 8.2/10.5 MB 5.4 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 8.5/10.5 MB 5.5 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 8.8/10.5 MB 5.5 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 9.1/10.5 MB 5.5 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 9.4/10.5 MB 5.5 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 9.6/10.5 MB 5.5 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 9.9/10.5 MB 5.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.3/10.5 MB 5.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.5/10.5 MB 5.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 10.5/10.5 MB 5.7 MB/s eta 0:00:00\n",
      "Installing collected packages: transformers\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.51.3\n",
      "    Uninstalling transformers-4.51.3:\n",
      "      Successfully uninstalled transformers-4.51.3\n",
      "Successfully installed transformers-4.52.0\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T19:22:47.758351Z",
     "start_time": "2025-05-20T19:22:47.740583Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import transformers\n",
    "print(transformers.__version__)"
   ],
   "id": "52229ddb8385c97a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.51.3\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T09:04:44.272582Z",
     "start_time": "2025-05-21T09:04:44.202280Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./wav2vec2-ft\",\n",
    "    per_device_train_batch_size=1,     \n",
    "    num_train_epochs=10,               \n",
    "    logging_steps=1,\n",
    "    learning_rate=1e-4,\n",
    "    warmup_steps=2,\n",
    "    save_total_limit=1,\n",
    "    remove_unused_columns=False,       \n",
    "    dataloader_num_workers=0,          \n",
    "    gradient_accumulation_steps=1,     \n",
    "    \n",
    ")\n"
   ],
   "id": "1723bcd8b28ea64",
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T09:04:45.202478Z",
     "start_time": "2025-05-21T09:04:45.197468Z"
    }
   },
   "cell_type": "code",
   "source": "model.gradient_checkpointing_enable()\n",
   "id": "e7b2ab893ad141d7",
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T09:04:49.305157Z",
     "start_time": "2025-05-21T09:04:49.289079Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "class CustomTrainer(Trainer):\n",
    "    def training_step(self, model, inputs, num_items_in_batch):\n",
    "        torch.cuda.empty_cache()\n",
    "        return super().training_step(model, inputs, num_items_in_batch)\n",
    "\n",
    "\n",
    "trainer = CustomTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset,\n",
    "    eval_dataset=dataset,\n",
    "    tokenizer=processor.feature_extractor,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n"
   ],
   "id": "f70edcfd5cb7ca28",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alper\\AppData\\Local\\Temp\\ipykernel_23232\\3815893847.py:9: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = CustomTrainer(\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T09:34:13.025578Z",
     "start_time": "2025-05-21T09:04:50.793022Z"
    }
   },
   "cell_type": "code",
   "source": "trainer.train()\n",
   "id": "8c4612ce09d84b76",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='40' max='40' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [40/40 26:59, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>7.864200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>8.080600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>5.835600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4.348500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>4.446600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>13.040600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>3.978200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>17.939300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>14.349600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>7.138400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>9.614000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>3.383100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>9.559500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>8.261300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>6.228500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>3.075000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>6.162500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>4.944700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>11.324400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>8.785100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>5.317800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>2.051100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>2.594900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>1.565100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>3.290000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>7.903400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>5.498400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>3.102500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>6.561000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.728800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>1.499900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>1.529700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>9.072100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>2.607800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>1.636900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>1.573600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>1.251000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>1.815400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>1.325600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.640500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=40, training_loss=5.548129811882973, metrics={'train_runtime': 1761.5929, 'train_samples_per_second': 0.023, 'train_steps_per_second': 0.023, 'total_flos': 3.58564176089568e+16, 'train_loss': 5.548129811882973, 'epoch': 10.0})"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "4d1540289d3d004e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "##TESTING",
   "id": "ff3f35c2db745a51"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T12:17:20.641852Z",
     "start_time": "2025-05-21T12:17:19.398706Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from evaluate import load\n",
    "wer_metric = load(\"wer\")  \n"
   ],
   "id": "dbf2ba607753d5c5",
   "outputs": [],
   "execution_count": 65
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "c67142d4547fdb88"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T12:32:17.368056Z",
     "start_time": "2025-05-21T12:32:13.712333Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torchaudio\n",
    "import torch\n",
    "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor\n",
    "model_name = \"facebook/wav2vec2-base-960h\"\n",
    "model=Wav2Vec2ForCTC.from_pretrained(model_name).to(\"cuda\")\n",
    "processor=Wav2Vec2Processor.from_pretrained(model_name)\n",
    "speech, sr=torchaudio.load(\"test_data/mytest.wav\")\n",
    "if speech.shape[0] > 1:\n",
    "    speech = speech.mean(dim=0)\n",
    "if sr != 16000:\n",
    "    resampler=torchaudio.transforms.Resample(sr, 16000)\n",
    "    speech=resampler(speech)\n",
    "inputs = processor(speech, sampling_rate=16000, return_tensors=\"pt\", padding=True)\n",
    "print(\"Input shape to model:\", inputs[\"input_values\"].shape)\n",
    "inputs = {k: v.to(\"cuda\") for k, v in inputs.items()}\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    logits = model(**inputs).logits\n",
    "    pred_ids = torch.argmax(logits, dim=-1)\n",
    "text = processor.batch_decode(pred_ids)[0]\n",
    "print(\"Transcript:\", text)\n"
   ],
   "id": "87ff0eb220cc3df9",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to model: torch.Size([1, 245419])\n",
      "Transcript: HA I AM MY PAR I AM TWENTY THREE YEARS OLD I AM AN A A SUTONTE TA YOR TEPEUNIVERSITY THIS IS OUR SPEECI TO TAXE PROJECT FOR MISHION EARNING FOR AT GAR COURSE LET'S SEE HOW I GRET THE MOTHER IS\n"
     ]
    }
   ],
   "execution_count": 76
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T12:32:31.302882Z",
     "start_time": "2025-05-21T12:32:31.278077Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with torch.no_grad():\n",
    "    logits = model(**inputs).logits\n",
    "\n",
    "pred_ids = torch.argmax(logits, dim=-1)\n"
   ],
   "id": "58f9fa02f9006853",
   "outputs": [],
   "execution_count": 77
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T12:33:28.330362Z",
     "start_time": "2025-05-21T12:33:28.316522Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "hyp=processor.batch_decode(pred_ids, skip_special_tokens=True)[0]\n",
    "print(\"Predicted text:\", hyp)\n"
   ],
   "id": "daf3fcd17ab9c320",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted text: HA I AM MY PAR I AM TWENTY THRE YEARS OLD I AM AN A A SUTONTE TA YOR TEPEUNIVERSITY THIS IS OUR SPECI TO TAXE PROJECT FOR MISHION EARNING FOR AT GAR COURSE LET'S SE HOW I GRET THE MOTHER IS\n"
     ]
    }
   ],
   "execution_count": 83
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T16:37:19.011294Z",
     "start_time": "2025-05-21T16:37:17.613547Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "ref = \"hi i am alper i am 23 years old i am an ai student at hacettepe university this is our speech to text project for machine learning for healthcare course lets see how accurate the model is\"\n",
    "ref=ref.upper()\n",
    "wer_metric=load(\"wer\")\n",
    "wer_score = wer_metric.compute(predictions=[hyp], references=[ref])\n",
    "print(\"Reference         :\", ref)\n",
    "print(\"Hypothesis        :\", hyp)\n",
    "#print(\"WER               :\", wer(ref, hyp))\n",
    "print(f\"WER               : {wer_score:.3f}\")\n"
   ],
   "id": "ae84f92f4d6fb940",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference         : HI I AM ALPER I AM 23 YEARS OLD I AM AN AI STUDENT AT HACETTEPE UNIVERSITY THIS IS OUR SPEECH TO TEXT PROJECT FOR MACHINE LEARNING FOR HEALTHCARE COURSE LETS SEE HOW ACCURATE THE MODEL IS\n",
      "Hypothesis        : HA I AM MY PAR I AM TWENTY THRE YEARS OLD I AM AN A A SUTONTE TA YOR TEPEUNIVERSITY THIS IS OUR SPECI TO TAXE PROJECT FOR MISHION EARNING FOR AT GAR COURSE LET'S SE HOW I GRET THE MOTHER IS\n",
      "WER               : 0.595\n"
     ]
    }
   ],
   "execution_count": 85
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
